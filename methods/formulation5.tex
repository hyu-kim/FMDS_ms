\documentclass{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%% Setup %%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[margin=3.3cm]{geometry}
% \usepackage{fullpage}
\usepackage{fmtcount} % 1st, 2nd...
\usepackage[english]{babel}
\usepackage{kotex}
\usepackage{soul} % spacing
\usepackage{enumerate} % change enum label
\usepackage{framed} % frame pagebreak

%%%%% Math, Code 
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amscd}
\usepackage{array}
\usepackage{mathtools} 
\usepackage{verbatim}
\usepackage{fancyvrb} % verbatim
\usepackage{algpseudocode}
\usepackage{algorithm}

%%%%% Graphic, Figure, Table
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{xcolor}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{multirow} % table
\usepackage{diagbox} % table
\usepackage{booktabs} % pretty table
\usepackage{colortbl} % color cells
\usepackage{longtable} % table to next page
\usepackage{rotating}
\usepackage{lscape} % landscape page
\usepackage{pdfpages} % insert external pdf file
\usepackage{wrapfig} % wrap fig, tbl with text
\usepackage{tikz}  % draw
\usetikzlibrary{
    arrows, decorations.pathmorphing, decorations.markings,
    backgrounds, fit, positioning, shapes.symbols, chains
}

%%%%% Bib, Cite
\usepackage{url}
\usepackage{cite}
\usepackage{fancyref}
\usepackage{hyperref}
% \addbibresource{thesisref.bib}

%%%%%% Setup
\captionsetup{compatibility=false} %subfig
\hypersetup{colorlinks=true, linkcolor=blue, urlcolor=blue}

\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{dfn}{Definition}
\newtheorem{ex}{Example}
\newtheorem{cmt}{Cmt}[section]
\newtheorem{rmk}{Remark}[section]
\newcommand{\rb}[1]{\raisebox{-.5em}[0pt]{#1}}
%\renewcommand{\baselinestretch}{1.9}
\renewcommand{\mid}{\, | \ , }
\newcommand{\1}{{\rm 1}\kern-0.24em{\rm I}}
%\newcommand{\eighth}{{\textstyle \frac{1}{8}}}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\bbr}{\mathbb{R}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\title{Stochastic Gradient Descent approach}
\author{HK}
\date{January 30, 2023}

\begin{document}

\maketitle
\section*{Motivation}
Our previous approach using majorization did not converge when the hyperparameter $\lambda$ was large ($\lambda>1$); this is because the confirmatory (classification) term was non-convex. We tackle the problem by using stochastic descent gradient as proposed by \cite{zheng}. 

Consider a balanced design where the number of total observations is $N$, and each observation $x_i$ is $S$-dimensional, pertaining to a set of labels $y_i\in\{0,1\}$ for every $i=1\cdots N$. Based on the observations $(x_1,\cdots x_N)$, a distance matrix is obtained as $\mathbf{d}=[d_{ij}]\in\bbr^{N\times N}$.

Now given the distance $\mathbf{d}$, we seek a two-dimensional configuration $\mathbf{z} = (\mathbf{z}_1, \cdots, \mathbf{z}_N) \in \bbr^{N \times 2}$, that best represents the original dimension by the following criteria. 

\begin{equation}\label{eq:mds}
    O(\mathbf{z}) = \underbrace{\frac{1}{2}\sum_{i,j} (d_{ij} - \| \mathbf{z}_i - \mathbf{z}_j \|_2 )^2}_\text{MDS term} + \lambda\cdot \underbrace{\frac{1}{2} \left|\sum_{i,j} [1- (f_{\mathbf{z}}(\Phi_o)+1)\1\{y_i = y_j\}] \|\mathbf{z}_i - \mathbf{z}_j\|_2^2\right|}_\text{Confirmatory term}
\end{equation}
where $\Phi_o$ is a ratio constant expressed in terms of the distance $\mathbf{d}$ and labels $y_i$, defined as

$$
\Phi_o (\mathbf{d}, y) \vcentcolon= \frac{\sum_{i,j} \1\{y_i \neq y_j\} d_{ij}^2}{\sum_{i,j} \1\{y_i = y_j\}d_{ij}^2},
$$
and where $f_\mathbf{z}(\Phi_o):\bbr\rightarrow\bbr$ is a mapping function which is determined by the configuration $\mathbf{z}$. An exact derivation of $f_\mathbf{z}$ and a detailed description on the confirmatory term in Equation (\ref{eq:mds}) is described in \hyperref[sec:supp]{Appendix}. Given Equation (\ref{eq:mds}), we want to find an optimal configuration $\mathbf{z}^*$ such that $\mathbf{z}^* = \argmin_{(\mathbf{z}_1, \cdots, \mathbf{z}_N)} O(\mathbf{z}).$


\section*{Derivation of stochastic gradient descent} 
Now we move on to minimize $O(\mathbf{z})$ using SGD algorithm. First, observe that

\begin{align}
O(\mathbf{z}) &= \frac{1}{2}\sum_{i,j} (d_{ij} - \| \mathbf{z}_i - \mathbf{z}_j \|_2 )^2 + \lambda\cdot \frac{1}{2} \left|\sum_{i,j} [1- (f_{\mathbf{z}}(\Phi_o)+1)\1\{y_i = y_j\}] \|\mathbf{z}_i - \mathbf{z}_j\|_2^2\right| \\
&= \sum_{i,j}\,\frac{1}{2}(d_{ij}-\|\mathbf{z}_i-\mathbf{z}_j\|_2)^2 + \frac{1}{2}\lambda\delta (\mathbf{z}) [1- (f_{\mathbf{z}}(\Phi_o)+1)\epsilon_{ij}] \|\mathbf{z}_i - \mathbf{z}_j\|_2^2 \label{eq:del}\\
&\coloneqq \sum_{i,j}\,O_{ij}(\mathbf{z})
\end{align}
where we have defined

$$
\delta (\mathbf{z}) = \text{sign}\,\sum_{i,j} [1- (f_{\mathbf{z}}(\Phi_o)+1)\epsilon_{ij}] \|\mathbf{z}_i - \mathbf{z}_j\|_2^2, \quad\epsilon_{ij} = \1\{y_i = y_j\}
$$
in Equation \ref{eq:del}. For SGD, we use $O_{ij}(\mathbf{z})$ and update the configuration $\mathbf{z} \leftarrow \mathbf{z} - \eta\nabla O_{ij}(\mathbf{z})$ on every epoch.

Next, we obtain a partial derivative of $O_{ij}(\mathbf{z})$ by $\mathbf{z}$. For each $i\in[N]$ observe that

\begin{align}
\frac{\partial O_{ij}}{\partial\mathbf{z}_i} &= \frac{\partial}{\partial\mathbf{z}_i}\,\frac{1}{2}(d_{ij}-\|\mathbf{z}_i-\mathbf{z}_j\|_2)^2 + \frac{1}{2}\lambda\delta(\mathbf{z})[1- (f_{\mathbf{z}}(\Phi_o)+1)\epsilon_{ij}]\cdot\|\mathbf{z}_i-\mathbf{z}_j\|_2^2 \\
&= -(d_{ij}-\|\mathbf{z}_i-\mathbf{z}_j\|_2)\cdot\frac{\mathbf{z}_i-\mathbf{z}_j}{\|\mathbf{z}_i-\mathbf{z}_j\|_2} + \lambda\delta(\mathbf{z})[1- (f_{\mathbf{z}}(\Phi_o)+1)\epsilon_{ij}](\mathbf{z}_i-\mathbf{z}_j) \\
&= \left\{1-\frac{d_{ij}}{\|\mathbf{z}_i-\mathbf{z}_j\|_2}+\lambda\delta(\mathbf{z})[1- (f_{\mathbf{z}}(\Phi_o)+1)\epsilon_{ij}]\right\}(\mathbf{z}_i-\mathbf{z}_j),
\end{align}
which allows us to proceed for any $k\in[N]$,

\begin{equation} \label{eq:partial}
\frac{\partial O_{ij}}{\partial\mathbf{z}_k} = \begin{cases}
    \left[1-\frac{d_{ij}}{\|\mathbf{z}_i-\mathbf{z}_j\|_2}+\lambda\delta(\mathbf{z})[1- (f_{\mathbf{z}}(\Phi_o)+1)\epsilon_{ij}]\right](\mathbf{z}_i-\mathbf{z}_j), & \text{if } k=i \\
    \left[\frac{d_{ij}}{\|\mathbf{z}_i-\mathbf{z}_j\|_2}-1-\lambda\delta(\mathbf{z})[1- (f_{\mathbf{z}}(\Phi_o)+1)\epsilon_{ij}]\right](\mathbf{z}_i-\mathbf{z}_j), & \text{elseif } k=j \\
    0, & \text{else}
\end{cases}
\end{equation}

\begin{algorithm}
\caption{SGD for pseudo \textit{F}-informed MDS}
For epoch $t$, arbitrarily choose $i,j$ each from $\{1,2,\cdots N\}$ then for every $k\in[N]$ update
$$
\mathbf{z}_{k}^{(t+1)} = \mathbf{z}_{k}^{(t)} - \eta^{(t)}\frac{\partial}{\partial\mathbf{z}_{k}^{(i)}} O_{ij}(\mathbf{z}_{k}^{(t)}),
$$
with a (time-decaying) step size $\eta^{(t)}$, and where
\begin{equation}
\frac{\partial}{\partial\mathbf{z}_k}O_{ij}(\mathbf{z}_{k}^{(t)}) = \begin{cases}
    \left[1-\frac{d_{ij}}{\|\mathbf{z}^{(t)}_i-\mathbf{z}^{(t)}_j\|_2}+\lambda\delta(\mathbf{z}^{(t)})[1- (f_{\mathbf{z}}(\Phi_o)+1)\epsilon_{ij}]\right](\mathbf{z}^{(t)}_i-\mathbf{z}^{(t)}_j), & \text{if } k=i \\
    \left[\frac{d_{ij}}{\|\mathbf{z}^{(t)}_i-\mathbf{z}^{(t)}_j\|_2}-1-\lambda\delta(\mathbf{z}^{(t)})[1- (f_{\mathbf{z}}(\Phi_o)+1)\epsilon_{ij}]\right](\mathbf{z}^{(t)}_i-\mathbf{z}^{(t)}_j), & \text{elseif } k=j \\
    0, & \text{else}.
\end{cases}
\end{equation}

Initial value can be obtained from a pure MDS.
\end{algorithm}


\section*{(Appendix) Derivation of mapping function $f_\mathbf{z}(\Phi_o)$}\label{sec:supp}

The confirmatory term in Equation (\ref{eq:mds}) originates in an effort to minimize a difference in the distribution of pseudo $F$ of the original and two-dimensional data, represented by the \textit{p}-values of each pseudo $F$ statistics. Here \textit{p}-value is obtained by a quantile of pseudo $F$ among its distribution of a set of permuted labels \cite{anderson01}. 

To estimate the closest pseudo $F$ minimizing the difference in \textit{p}-values, we first derive the following statistics
\begin{equation}
\Phi_o^\Pi = \frac{\sum_{i,j} \1\{y_i^\Pi \neq y_j^\Pi\} d_{ij}^2}{\sum_{i,j} \1\{y_i^\Pi = y_j^\Pi\}d_{ij}^2}, \quad 
\Phi_\mathbf{z}^\Pi = \frac{\sum_{i,j} \1\{y_i^\Pi \neq y_j^\Pi\} \|\mathbf{z}_i - \mathbf{z}_j\|_2^2}{\sum_{i,j} \1\{y_i^\Pi = y_j^\Pi\} \|\mathbf{z}_i - \mathbf{z}_j\|_2^2}, \label{eq:map1}
\end{equation}
where the superscript $\Pi$ denotes a permutation of labels $\{y_i\}$. 

Next step is to correlate $\Phi_o^\Pi$ and $\Phi_\mathbf{z}^\Pi$ by repeating the permutation and performing a local regression (LOESS) on the pair set. This allows us to obtain an approximation of function $f_\mathbf{z}(\cdot)$ that maps $\Phi_o$ to $\Phi_\mathbf{z}$ (Figure \ref{fig:fval}).

\begin{figure}[h]
    \centering
    \includegraphics[width=5in]{images/formulation/Fval.pdf}
    \caption{Correlation plot of pseudo F in the orginal and two-dimensional by permuting $y$ labels over 1,000 iteration. Created after setting a hyperparameter $\lambda$ in $F$-informed MDS (left, 0.3; right, 0).}
    \label{fig:fval}
\end{figure}

In addition, we explain why $\Phi_o$, $\Phi_\mathbf{z}$ in Equation (\ref{eq:map1}) represent our pseudo $F$ statistics in terms of obtaining the $p$-values. This is simply by observing the pseudo $F$ of the original and two-dimensional configuration,
$$
F_\mathbf{z} = (N-2)\cdot\frac{\sum_{i,j}\|\mathbf{z}_i - \mathbf{z}_j\|_2^2}{\sum_{i,j}\1\{y_i = y_j\}\|\mathbf{z}_i - \mathbf{z}_j\|_2^2} = (N-2)(1+\Phi_\mathbf{z}), 
$$
$$
F_o = (N-2)\cdot\frac{\sum_{i,j} d_{ij}^2}{\sum_{i,j} \1\{y_i = y_j\}d_{ij}^2} = (N-2)(1+\Phi_o),
$$
so it suggests that the same $p$-value can be obtained by calculating a quantile of $\Phi$-distribution.

Finally, we derive the confirmatory term in Equation (\ref{eq:mds}) by observing

\begin{align}
\argmin_\mathbf{z}\,&\left|\Phi_\mathbf{z}(\mathbf{z}) - f_\mathbf{z}(\Phi_o)\right| \\
&= \argmin_\mathbf{z}\,\left|\frac{\sum_{i,j} \1\{y_i \neq y_j\} \|\mathbf{z}_i - \mathbf{z}_j\|_2^2}{\sum_{i,j} \1\{y_i = y_j\} \|\mathbf{z}_i - \mathbf{z}_j\|_2^2} - f_\mathbf{z}(\Phi_o)\right| \\
&\approx\argmin_\mathbf{z}\,\left|\sum_{i,j}\1\{y_i \neq y_j\} \|\mathbf{z}_i - \mathbf{z}_j\|_2^2 - f_\mathbf{z}(\Phi_o)\cdot \sum_{i,j} \1\{y_i = y_j\} \|\mathbf{z}_i - \mathbf{z}_j\|_2^2\right| \\
&=\argmin_\mathbf{z}\,\left|\sum_{i,j} \left[1- (f_\mathbf{z}(\Phi_o)+1)\1\{y_i = y_j\}\right]\|\mathbf{z}_i - \mathbf{z}_j\|_2^2\right|.
\end{align}

A side note, a remaining work is to find a relationship between the MDS term $f(\mathbf{z})$ and a boundedness of the denominator term $\sum_{i,j} \1\{y_i = y_j\} \|\mathbf{z}_i - \mathbf{z}_j\|_2^2$. It would allow us to determine how much $g(\mathbf{z^*})$ can deviate from $F_{\text{MDS}}(\mathbf{z^*}) - F_0$.


\begin{thebibliography}{}

\bibitem{borg}
I.\,Borg and P.\,J.\,F.\,Groenen, Modern multidimensional scaling: Theory and applications, 2nd ed. Springer series in statistics, Springer New York, NY (2005).
\bibitem{zheng}
J.\,X.\,Zheng, S.\,Pawar and D.\,F.\,M.\,Goodman, Graph Drawing by Stochastic Gradient Descent, IEEE Transactions on Visualization and Computer Graphics, vol. 25, no. 9, pp. 2738-2748 (2019).
\bibitem{anderson01}
Anderson, M.J. (2001), A new method for non-parametric multivariate analysis of variance. Austral Ecology, 26, pp. 32-46.

\end{thebibliography}

\end{document}
